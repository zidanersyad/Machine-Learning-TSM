{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872d739a-b9aa-4925-9b27-80f051c928bf",
   "metadata": {},
   "source": [
    "### LAYER 1: CONFIGURATION & SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7138dc64-92a2-4a24-b8ef-4d4f52fe0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "import joblib\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "# Setup stopwords\n",
    "nltk_stopword = stopwords.words('indonesian')\n",
    "stopword_id_factory = StopWordRemoverFactory()\n",
    "sastrawi_stopword = stopword_id_factory.get_stop_words()\n",
    "\n",
    "additional_stopwords = [\n",
    "    \"nya\",\"sih\",\"mah\",\"r\",\"n\",\"kalo\",\"tuh\",\"ah\",\"b\",\"l\",\"deh\",\"kah\",\"oh\",\"ih\",\"dih\",\"bro\",\"cuy\",\n",
    "    \"sa\",\"ya\",\"ok\",\"heh\",\"lo\",\"lu\",\"i\",\"ii\",\"ti\",\"ki\",\"bal\",\"t\",\"al\",\"qur\",\"je\",\"ta\",\"oy\",\"li\",\n",
    "    \"h\",\"ar\",\"p\",\"as\",\"hi\",\"v\",\"nge\",\"wkwkwk\",\"dll\",\"nih\",\"ku\",\"a\",\"iii\",\"si\",\"lho\",\"gua\",\"gue\",\n",
    "    \"gu\",\"ay\",\"et\",\"opo\",\"ai\",\"un\",\"lol\",\"sus\",\"es\",\"ut\",\"iki\",\"zu\",\"ane\",\"ab\",\"mil\",\"wie\",\"ev\",\n",
    "    \"f\",\"kd\",\"st\",\"kar\",\"to\",\"ipo\",\"och\",\"einie\",\"sek\",\"lee\",\"eriii\",\"vii\",\"ile\",\"mi\",\"sel\",\"weh\",\n",
    "    \"sb\",\"ra\",\"iin\",\"ske\",\"sur\",\"um\",\"xde\",\"iku\",\"bla\",\"hai\",\"xl\",\"des\",\"duh\",\"we\",\"cc\",\"ag\",\"wan\",\n",
    "    \"po\",\"nin\",\"yth\",\"ipu\",\"auch\",\"wes\",\"yaudah\",\"tir\",\"wkwk\",\"wk\",\"mu\",\"les\",\"kor\",\"ppp\",\"au\",\n",
    "    \"und\",\"sia\",\"gp\",\"ist\",\"ye\",\"im\",\"ha\",\"hebas\",\"at\",\"pe\",\"bua\",\"qs\",\"bo\",\"ich\",\"they\",\"if\",\n",
    "    \"etc\",\"tg\",\"too\",\"als\",\"ngopo\",\"gi\",\"up\",\"ora\",\"ve\",\"kok\",\"go\",\"bv\",\"oi\",\"nom\",\"tr\",\"ui\",\n",
    "    \"ana\",\"aku\",\"ahy\",\"kat\",\"tri\",\"iya\",\"tau\",\"kau\",\"bal\",\"an\",\"dah\",\"loh\",\"mbak\",\"e\",\"mak\",\n",
    "    \"asa\",\"ayo\",\"ph\",\"vs\",\"wa\",\"xa\",\"jaku\",\"xe\",\"xf\",\"rp\",\"su\",\"ibl\",\"woi\",\"nak\",\"pn\",\"guys\",\n",
    "    \"vub\",\"x\",\"aji\",\"my\",\"you\",\"the\",\"this\",\"is\",\"and\",\"of\",\"your\",\"victim\",\"life\",\"why\",\n",
    "    \"what\",\"one\",\"no\",\"ber\",\"dm\",\"hehe\",\"he\",\"all\",\"but\",\"okay\",\"just\",\"download\",\"had\",\n",
    "    \"hahahaha\",\"niin\",\"walaun\",\"try\",\"xb\",\"ygy\",\"bi\",\"ei\",\"hah\",\"noh\",\"kapai\",\"oke\",\"min\",\n",
    "    \"sop\",\"dek\",\"ala\",\"plis\",\"rai\",\"gwe\",\"en\",\"zul\",\"ooo\",\"aing\",\"its\",\"wae\",\"gws\",\"test\",\n",
    "    \"bas\",\"by\",\"didu\",\"true\",\"kna\",\"ho\",\"atuh\",\"az\",\"pm\",\"bot\",\"akan\",\"pis\",\"acc\",\"idk\",\n",
    "    \"sape\",\"kwa\",\"mohon\",\"minta\",\"ybs\",\"tolong\",\"segera\",\"lanjut\",\"baik\" \n",
    "]\n",
    "\n",
    "STOPWORDS = list(set(nltk_stopword + sastrawi_stopword + additional_stopwords))\n",
    "\n",
    "# Setup stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_file': 'Data Olah.csv',\n",
    "    'min_df': 3,\n",
    "    'max_df': 0.95,\n",
    "    'top_n_tags': 8,\n",
    "    'top_k_output': 10,\n",
    "    'frequency_weight': 0.7,\n",
    "    'relative_weight': 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36dfd6-a3f7-4aeb-aabe-136a863c8785",
   "metadata": {},
   "source": [
    "### LAYER 2: DATA LOADING & COLUMN DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27df5061-7750-4b06-9210-1a8a1d3ff1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_col(df, candidates):\n",
    "    \"\"\"Deteksi kolom berdasarkan daftar kandidat nama\"\"\"\n",
    "    for cand in candidates:\n",
    "        for c in df.columns:\n",
    "            if cand.lower() == c.lower().strip():\n",
    "                return c\n",
    "    # Fuzzy search\n",
    "    for cand in candidates:\n",
    "        for c in df.columns:\n",
    "            if cand.lower() in c.lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_and_detect_columns(filepath):\n",
    "    \"\"\"Load data dan deteksi kolom yang diperlukan\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Dataset loaded: {len(df)} rows\")\n",
    "    \n",
    "    columns = {\n",
    "        'summary': find_col(df, ['Summary','summary','Summary_x']),\n",
    "        'judul': find_col(df, ['Judul Request_x','Judul_Request_x','Judul Request x','judul request_x','judul']),\n",
    "        'description': find_col(df, ['Description','Deskripsi','description','deskripsi']),\n",
    "        'status_x': find_col(df, ['Status_x','Status x','status_x','status']),\n",
    "        'status_y': find_col(df, ['Status_y','Status y','status_y']),\n",
    "        'engineer': find_col(df, ['Engineer','engineer','Assignee','assignee','petugas','pegawai']),\n",
    "        'request_name': find_col(df, ['Request name','Request_name','request_name','request name'])\n",
    "    }\n",
    "    \n",
    "    print(\"\\n=== Detected Columns ===\")\n",
    "    for key, val in columns.items():\n",
    "        print(f\"{key}: {val}\")\n",
    "    \n",
    "    if columns['engineer'] is None:\n",
    "        raise ValueError(\"Kolom Engineer tidak terdeteksi! Set kolom engineer secara manual.\")\n",
    "    \n",
    "    return df, columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a4059d-0f1a-4322-9213-5223709c3d65",
   "metadata": {},
   "source": [
    "### LAYER 3: TEXT PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba59dad-c0c2-49c7-b8f2-e88a064d03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    \"\"\"Membersihkan teks dari username, URL, simbol, dan angka\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\", \"\", text)\n",
    "    text = re.sub(r'''(?i)\\b((?:https|http?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»\"\"'']))''', \"\", text)\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\", \"\", text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Filter kata dengan 3 huruf berurutan tanpa konsonan\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if len(token) > 2:\n",
    "            has_three_vowels = False\n",
    "            for i in range(len(token) - 2):\n",
    "                substring = token[i:i+3]\n",
    "                if all(char in 'aiueo' for char in substring.lower()):\n",
    "                    has_three_vowels = True\n",
    "                    break\n",
    "            if not has_three_vowels:\n",
    "                filtered_tokens.append(token)\n",
    "    \n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "\n",
    "def casefolding(text):\n",
    "    \"\"\"Konversi teks ke lowercase\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def stopwords_removal(text):\n",
    "    \"\"\"Menghapus stopwords dari teks\"\"\"\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in STOPWORDS]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "def stemming(text):\n",
    "    \"\"\"Melakukan stemming pada teks\"\"\"\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "\n",
    "def tokenizing(text):\n",
    "    \"\"\"Tokenisasi teks\"\"\"\n",
    "    return nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df, columns):\n",
    "    \"\"\"Pipeline preprocessing lengkap untuk DataFrame\"\"\"\n",
    "    print(\"\\n=== Preprocessing Data ===\")\n",
    "    \n",
    "    # Gabungkan kolom untuk text_for_skill\n",
    "    df['summary_clean'] = df[columns['summary']].fillna(\"\") if columns['summary'] else \"\"\n",
    "    df['judul_clean'] = df[columns['judul']].fillna(\"\") if columns['judul'] else \"\"\n",
    "    df['description_clean'] = df[columns['description']].fillna(\"\") if columns['description'] else \"\"\n",
    "    \n",
    "    df['text_for_skill'] = (df['summary_clean'].astype(str) + \" \" + \n",
    "                            df['judul_clean'].astype(str) + \" \" + \n",
    "                            df['description_clean'].astype(str)).str.strip()\n",
    "    \n",
    "    # Pipeline preprocessing\n",
    "    print(\"Applying text cleaning pipeline...\")\n",
    "    df['processed_text'] = df['text_for_skill'].apply(cleaning_text)\n",
    "    df['processed_text'] = df['processed_text'].apply(casefolding)\n",
    "    df['processed_text'] = df['processed_text'].apply(stopwords_removal)\n",
    "    df['processed_text'] = df['processed_text'].apply(stemming)\n",
    "    df['processed_tokens'] = df['processed_text'].apply(tokenizing)\n",
    "    df['text_join'] = df['processed_tokens'].apply(\n",
    "        lambda toks: \" \".join(toks) if isinstance(toks, (list, tuple)) else str(toks)\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ba920-a79b-4d27-8e8c-0bdfb46c17fc",
   "metadata": {},
   "source": [
    "### LAYER 4: DATA FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c7a26b-1a1e-4389-81ea-f54f2c644aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_status(v):\n",
    "    \"\"\"Normalisasi status\"\"\"\n",
    "    if pd.isna(v):\n",
    "        return None\n",
    "    return str(v).strip()\n",
    "\n",
    "\n",
    "def include_for_skill(row, col_engineer):\n",
    "    \"\"\"Tentukan apakah row diikutkan dalam skill profiling\"\"\"\n",
    "    sx = (row['status_x_norm'] or \"\").lower() if row['status_x_norm'] is not None else None\n",
    "    sy = (row['status_y_norm'] or \"\").lower() if row['status_y_norm'] is not None else None\n",
    "    \n",
    "    # Exclude cancelled/rejected\n",
    "    if sx == 'cancelled' and sy in {'cancelled','rejected'}:\n",
    "        return False\n",
    "    if sy in {'cancelled','rejected'}:\n",
    "        return False\n",
    "    \n",
    "    # Include jika status handled dan ada engineer + text\n",
    "    if sx in {'resolved','closed','in progress','need follow up','submitted','waiting for 3rd party','escalated'}:\n",
    "        if pd.notna(row.get(col_engineer)) and row['text_join'].strip() != '':\n",
    "            return True\n",
    "    \n",
    "    if sy in {'completed','assigned','accepted','waiting'}:\n",
    "        if pd.notna(row.get(col_engineer)) and row['text_join'].strip() != '':\n",
    "            return True\n",
    "    \n",
    "    # Fallback: engineer exists dan text exists\n",
    "    if pd.notna(row.get(col_engineer)) and row['text_join'].strip() != '':\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def filter_skill_data(df, columns):\n",
    "    \"\"\"Filter data untuk skill profiling\"\"\"\n",
    "    df['status_x_norm'] = df[columns['status_x']].apply(norm_status) if columns['status_x'] else None\n",
    "    df['status_y_norm'] = df[columns['status_y']].apply(norm_status) if columns['status_y'] else None\n",
    "    \n",
    "    df['include_skill'] = df.apply(lambda row: include_for_skill(row, columns['engineer']), axis=1)\n",
    "    print(f\"Rows included for skill profiling: {df['include_skill'].sum()} / {len(df)}\")\n",
    "    \n",
    "    df_skill = df[df['include_skill']].copy().reset_index(drop=True)\n",
    "    print(f\"Final skill dataset: {len(df_skill)} rows\")\n",
    "    \n",
    "    return df_skill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f34ab-ce0d-4b9d-9982-020a5b918c60",
   "metadata": {},
   "source": [
    "### LAYER 5: FEATURE EXTRACTION (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59428aa4-4d8c-4e85-baf4-0c0d86a4e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tfidf_features(df_skill, config):\n",
    "    \"\"\"Ekstraksi fitur TF-IDF dari text\"\"\"\n",
    "    print(\"\\n=== TF-IDF Vectorization ===\")\n",
    "    \n",
    "    tfidf_tag = TfidfVectorizer(min_df=config['min_df'], max_df=config['max_df'])\n",
    "    texts = df_skill['text_join'].fillna(\"\").tolist()\n",
    "    X_tfidf = tfidf_tag.fit_transform(texts)\n",
    "    terms = tfidf_tag.get_feature_names_out()\n",
    "    \n",
    "    print(f\"TF-IDF vocab size: {len(terms)}\")\n",
    "    \n",
    "    return X_tfidf, tfidf_tag, terms\n",
    "\n",
    "\n",
    "def top_n_terms_from_vector(vec, terms, n=8):\n",
    "    \"\"\"Ekstrak top N terms dari TF-IDF vector\"\"\"\n",
    "    arr = vec.toarray().ravel()\n",
    "    if arr.sum() == 0:\n",
    "        return []\n",
    "    idx = np.argsort(arr)[-n:][::-1]\n",
    "    return [terms[i] for i in idx if arr[i] > 0]\n",
    "\n",
    "\n",
    "def extract_tags_from_tfidf(X_tfidf, terms, topn=8):\n",
    "    \"\"\"Ekstrak top tags dari setiap dokumen\"\"\"\n",
    "    print(\"Extracting top tags per ticket...\")\n",
    "    top_tags_list = []\n",
    "    for i in tqdm(range(X_tfidf.shape[0]), desc=\"Extracting tags\"):\n",
    "        top_tags_list.append(top_n_terms_from_vector(X_tfidf[i], terms, n=topn))\n",
    "    return top_tags_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d6fbce-6ac8-4c5f-aa70-3d4580a65dd6",
   "metadata": {},
   "source": [
    "### LAYER 6: SKILL PROFILING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f07a94-da26-4758-923a-036ef3d71fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_engineer_skill_profiles(df_skill, col_engineer, config):\n",
    "    \"\"\"Build skill profiles untuk setiap engineer dengan scoring\"\"\"\n",
    "    print(\"\\n=== Building Engineer Skill Profiles with Scores ===\")\n",
    "    \n",
    "    # Hitung frekuensi tag per engineer\n",
    "    eng_tag_counts = defaultdict(Counter)\n",
    "    for _, row in df_skill.iterrows():\n",
    "        eng = row[col_engineer]\n",
    "        if pd.isna(eng) or str(eng).strip() == \"\":\n",
    "            continue\n",
    "        tags = row['extracted_tags'] or []\n",
    "        eng_tag_counts[eng].update(tags)\n",
    "    \n",
    "    # Konversi ke DataFrame dan hitung skor\n",
    "    rows = []\n",
    "    for eng, ctr in eng_tag_counts.items():\n",
    "        total_tickets = sum(ctr.values())\n",
    "        max_count = max(ctr.values()) if ctr else 1\n",
    "        \n",
    "        for tag, cnt in ctr.items():\n",
    "            # Skor kombinasi: frequency (normalized) + relative importance\n",
    "            frequency_score = cnt / max_count\n",
    "            relative_score = cnt / total_tickets\n",
    "            combined_score = (frequency_score * config['frequency_weight']) + \\\n",
    "                           (relative_score * config['relative_weight'])\n",
    "            \n",
    "            rows.append({\n",
    "                'engineer': eng,\n",
    "                'tag': tag,\n",
    "                'count': cnt,\n",
    "                'score': round(combined_score, 4)\n",
    "            })\n",
    "    \n",
    "    tag_scores_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Build profiles dengan skor\n",
    "    profiles = {}\n",
    "    for eng, g in tag_scores_df.groupby('engineer'):\n",
    "        profiles[eng] = dict(zip(g['tag'], g['score']))\n",
    "    \n",
    "    print(f\"Engineer profiles created: {len(profiles)} engineers\")\n",
    "    \n",
    "    return profiles, tag_scores_df\n",
    "\n",
    "\n",
    "def create_output_dataframe(profiles, topk=10):\n",
    "    \"\"\"Buat output DataFrame dengan engineer dan top_tags\"\"\"\n",
    "    engineer_skills_output = []\n",
    "    for eng, tag_scores in profiles.items():\n",
    "        # Sort by score descending\n",
    "        sorted_tags = sorted(tag_scores.items(), key=lambda x: -x[1])[:topk]\n",
    "        \n",
    "        # Format: \"tag1(score1), tag2(score2), ...\"\n",
    "        top_tags_str = \", \".join([f\"{tag}({score:.3f})\" for tag, score in sorted_tags])\n",
    "        \n",
    "        engineer_skills_output.append({\n",
    "            'engineer': eng,\n",
    "            'top_tags': top_tags_str\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(engineer_skills_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1ef366-820c-42d7-a5e2-4aaddda997d4",
   "metadata": {},
   "source": [
    "### LAYER 7: CENTROID BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4329ca96-f230-453e-ba9d-d1add6b77059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_engineer_centroids(df_skill, X_tfidf, col_engineer):\n",
    "    \"\"\"Build centroids untuk setiap engineer\"\"\"\n",
    "    print(\"\\n=== Building Engineer Centroids ===\")\n",
    "    \n",
    "    engineer_centroids = {}\n",
    "    for eng, idxs in df_skill.groupby(col_engineer).indices.items():\n",
    "        rows_tfidf = X_tfidf[list(idxs)]\n",
    "        centroid = rows_tfidf.mean(axis=0)\n",
    "        \n",
    "        if sparse.issparse(centroid):\n",
    "            centroid = centroid.tocsr()\n",
    "        elif isinstance(centroid, np.matrix):\n",
    "            centroid = csr_matrix(np.asarray(centroid))\n",
    "        elif isinstance(centroid, np.ndarray):\n",
    "            if centroid.ndim == 1:\n",
    "                centroid = centroid.reshape(1, -1)\n",
    "            centroid = csr_matrix(centroid)\n",
    "        \n",
    "        engineer_centroids[eng] = centroid\n",
    "    \n",
    "    print(f\"Engineer centroids created: {len(engineer_centroids)} engineers\")\n",
    "    return engineer_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803317fd-b203-41d0-bf4b-281c1cd97301",
   "metadata": {},
   "source": [
    "### LAYER 8: RANKING & RECOMMENDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f304feac-375e-4837-b4bf-7bc28b9c320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_by_centroid(ticket_text, centroids, tfidf_obj):\n",
    "    \"\"\"Ranking engineer berdasarkan centroid similarity\"\"\"\n",
    "    v = tfidf_obj.transform([ticket_text])\n",
    "    sims = {}\n",
    "    for eng, cent in centroids.items():\n",
    "        sim = cosine_similarity(v, cent)[0, 0]\n",
    "        sims[eng] = float(sim)\n",
    "    \n",
    "    # Normalize 0-1\n",
    "    maxv = max(sims.values()) if sims else 1.0\n",
    "    if maxv > 0:\n",
    "        sims = {k: v / maxv for k, v in sims.items()}\n",
    "    \n",
    "    return dict(sorted(sims.items(), key=lambda x: -x[1]))\n",
    "\n",
    "\n",
    "def get_candidates(ticket_text, centroids, tfidf_obj, topk=10, availability=None, workload=None):\n",
    "    \"\"\"Get top K engineer candidates dengan filter availability & workload\"\"\"\n",
    "    ranked = rank_by_centroid(ticket_text, centroids, tfidf_obj)\n",
    "    \n",
    "    result = []\n",
    "    for eng, sc in ranked.items():\n",
    "        if availability is not None:\n",
    "            if availability.get(eng, 0) == 0:\n",
    "                continue\n",
    "        if workload is not None:\n",
    "            if workload.get(eng, 1) < 0.2:\n",
    "                continue\n",
    "        result.append((eng, sc))\n",
    "        if len(result) >= topk:\n",
    "            break\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c7500-a374-4ec9-967d-a13f193f6af7",
   "metadata": {},
   "source": [
    "### LAYER 9: MODEL PERSISTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b6e0e9-109c-4ee6-9414-056b360109d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(profiles, engineer_centroids, tfidf_tag):\n",
    "    \"\"\"Save semua model ke disk\"\"\"\n",
    "    print(\"\\n=== Saving Models ===\")\n",
    "    \n",
    "    # Save profiles\n",
    "    joblib.dump(\n",
    "        {'tfidf_tag': tfidf_tag, 'profiles': profiles}, \n",
    "        'engineer_profiles_tags.joblib'\n",
    "    )\n",
    "    print(\"Saved: engineer_profiles_tags.joblib\")\n",
    "    \n",
    "    # Save centroids\n",
    "    joblib.dump(\n",
    "        {'tfidf_tag': tfidf_tag, 'centroids': engineer_centroids}, \n",
    "        'engineer_centroids_tfidf.joblib'\n",
    "    )\n",
    "    print(\"Saved: engineer_centroids_tfidf.joblib\")\n",
    "\n",
    "\n",
    "def save_output(engineer_skills_df):\n",
    "    \"\"\"Save output DataFrame\"\"\"\n",
    "    engineer_skills_df.to_csv('engineer_skills_with_scores.csv', index=False)\n",
    "    print(\"Saved: engineer_skills_with_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131897ad-81a0-4d0c-80c0-53f415af782c",
   "metadata": {},
   "source": [
    "### LAYER 10: MAIN PIPELINE ORCHESTRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cdb03d3-3262-47ff-a65d-7dfc21b34e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main pipeline execution\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ENGINEER SKILL PROFILING PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Layer 2: Load data\n",
    "    df, columns = load_and_detect_columns(CONFIG['data_file'])\n",
    "    \n",
    "    # Layer 3: Preprocess\n",
    "    df = preprocess_dataframe(df, columns)\n",
    "    \n",
    "    # Layer 4: Filter\n",
    "    df_skill = filter_skill_data(df, columns)\n",
    "    \n",
    "    # Layer 5: Extract TF-IDF\n",
    "    X_tfidf, tfidf_tag, terms = extract_tfidf_features(df_skill, CONFIG)\n",
    "    top_tags = extract_tags_from_tfidf(X_tfidf, terms, CONFIG['top_n_tags'])\n",
    "    df_skill['extracted_tags'] = top_tags\n",
    "    \n",
    "    # Layer 6: Build profiles\n",
    "    profiles, tag_scores_df = build_engineer_skill_profiles(\n",
    "        df_skill, columns['engineer'], CONFIG\n",
    "    )\n",
    "    engineer_skills_df = create_output_dataframe(profiles, CONFIG['top_k_output'])\n",
    "    \n",
    "    # Layer 7: Build centroids\n",
    "    engineer_centroids = build_engineer_centroids(df_skill, X_tfidf, columns['engineer'])\n",
    "    \n",
    "    # Layer 9: Save everything\n",
    "    save_models(profiles, engineer_centroids, tfidf_tag)\n",
    "    save_output(engineer_skills_df)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n=== Engineer Skills DataFrame ===\")\n",
    "    print(engineer_skills_df.head(10))\n",
    "    print(f\"\\nTotal engineers: {len(engineer_skills_df)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return engineer_skills_df, profiles, engineer_centroids, tfidf_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288e1c0-e737-4ab3-b4df-27940a898c75",
   "metadata": {},
   "source": [
    "### EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70fab49c-a25b-4662-a706-c896b955b19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENGINEER SKILL PROFILING PIPELINE\n",
      "================================================================================\n",
      "Dataset loaded: 24762 rows\n",
      "\n",
      "=== Detected Columns ===\n",
      "summary: Summary_x\n",
      "judul: Judul Request_x\n",
      "description: Description\n",
      "status_x: Status_x\n",
      "status_y: Status_y\n",
      "engineer: Engineer\n",
      "request_name: Request Name\n",
      "\n",
      "=== Preprocessing Data ===\n",
      "Applying text cleaning pipeline...\n",
      "Rows included for skill profiling: 22338 / 24762\n",
      "Final skill dataset: 22338 rows\n",
      "\n",
      "=== TF-IDF Vectorization ===\n",
      "TF-IDF vocab size: 3683\n",
      "Extracting top tags per ticket...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6447f04b80b444f7b026a44c64c256aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting tags:   0%|          | 0/22338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building Engineer Skill Profiles with Scores ===\n",
      "Engineer profiles created: 51 engineers\n",
      "\n",
      "=== Building Engineer Centroids ===\n",
      "Engineer centroids created: 51 engineers\n",
      "\n",
      "=== Saving Models ===\n",
      "Saved: engineer_profiles_tags.joblib\n",
      "Saved: engineer_centroids_tfidf.joblib\n",
      "Saved: engineer_skills_with_scores.csv\n",
      "\n",
      "=== Engineer Skills DataFrame ===\n",
      "                       engineer  \\\n",
      "0                    Aby Irawan   \n",
      "1      Achmad Koesnadi Alamsyah   \n",
      "2           Achmad Mahara Fauzy   \n",
      "3             Ade Ilham Mustofa   \n",
      "4              Adian Tampubolon   \n",
      "5                Adilah Ahsanah   \n",
      "6               Adithia Jovandy   \n",
      "7        Aldy Kurniawan Syafawi   \n",
      "8           Andhi Yudha Triawan   \n",
      "9  Anggito Anju Hartawan Manalu   \n",
      "\n",
      "                                            top_tags  \n",
      "0  outq(0.727), data(0.715), adhoc(0.678), restor...  \n",
      "1  vpn(0.714), access(0.648), akses(0.537), serve...  \n",
      "2  server(0.730), machine(0.693), non(0.610), vir...  \n",
      "3  data(0.735), maintenance(0.698), consolidated(...  \n",
      "4  email(0.716), zimbra(0.614), buat(0.562), moho...  \n",
      "5  server(0.728), hardware(0.485), client(0.364),...  \n",
      "6  database(0.740), restore(0.680), mohon(0.559),...  \n",
      "7  email(0.741), reset(0.610), services(0.565), p...  \n",
      "8  data(0.712), outq(0.614), adhoc(0.581), rekeni...  \n",
      "9  bale(0.717), bisnis(0.717), nasabah(0.538), ha...  \n",
      "\n",
      "Total engineers: 51\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY\n",
      "================================================================================\n",
      "\n",
      "=== TOP 10 ENGINEERS ===\n",
      "                       engineer  \\\n",
      "0                    Aby Irawan   \n",
      "1      Achmad Koesnadi Alamsyah   \n",
      "2           Achmad Mahara Fauzy   \n",
      "3             Ade Ilham Mustofa   \n",
      "4              Adian Tampubolon   \n",
      "5                Adilah Ahsanah   \n",
      "6               Adithia Jovandy   \n",
      "7        Aldy Kurniawan Syafawi   \n",
      "8           Andhi Yudha Triawan   \n",
      "9  Anggito Anju Hartawan Manalu   \n",
      "\n",
      "                                            top_tags  \n",
      "0  outq(0.727), data(0.715), adhoc(0.678), restor...  \n",
      "1  vpn(0.714), access(0.648), akses(0.537), serve...  \n",
      "2  server(0.730), machine(0.693), non(0.610), vir...  \n",
      "3  data(0.735), maintenance(0.698), consolidated(...  \n",
      "4  email(0.716), zimbra(0.614), buat(0.562), moho...  \n",
      "5  server(0.728), hardware(0.485), client(0.364),...  \n",
      "6  database(0.740), restore(0.680), mohon(0.559),...  \n",
      "7  email(0.741), reset(0.610), services(0.565), p...  \n",
      "8  data(0.712), outq(0.614), adhoc(0.581), rekeni...  \n",
      "9  bale(0.717), bisnis(0.717), nasabah(0.538), ha...  \n",
      "\n",
      "=== EXAMPLE: Skill Profile ===\n",
      "Engineer: Aby Irawan\n",
      "Skills: outq(0.727), data(0.715), adhoc(0.678), restore(0.628), lapor(0.616), mohon(0.218), form(0.193), minta(0.186), eod(0.162), core(0.162)\n"
     ]
    }
   ],
   "source": [
    "# Jalankan pipeline\n",
    "engineer_skills_df, profiles, engineer_centroids, tfidf_tag = main()\n",
    "\n",
    "# Lihat hasil\n",
    "print(\"\\n=== TOP 10 ENGINEERS ===\")\n",
    "print(engineer_skills_df.head(10))\n",
    "\n",
    "# Lihat detail satu engineer\n",
    "print(\"\\n=== EXAMPLE: Skill Profile ===\")\n",
    "if len(engineer_skills_df) > 0:\n",
    "    first_engineer = engineer_skills_df.iloc[0]['engineer']\n",
    "    print(f\"Engineer: {first_engineer}\")\n",
    "    print(f\"Skills: {engineer_skills_df.iloc[0]['top_tags']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13f12a-3021-465f-8c37-b851d3dad7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
